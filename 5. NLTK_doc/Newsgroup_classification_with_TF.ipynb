{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newsgroups_classification_simple_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:15.511431Z",
     "start_time": "2018-03-18T06:30:14.166826Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and processing\n",
    "TfidfVectorizer만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:17.994056Z",
     "start_time": "2018-03-18T06:30:16.366189Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['rec.sport.baseball', 'soc.religion.christian', 'comp.windows.x', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "\n",
    "X_train = newsgroups_train.data\n",
    "Y_train = newsgroups_train.target\n",
    "X_test = newsgroups_test.data\n",
    "Y_test = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Declare two vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:18.596146Z",
     "start_time": "2018-03-18T06:30:18.589694Z"
    }
   },
   "outputs": [],
   "source": [
    "# count_vectorizer = CountVectorizer(min_df=40)\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fitting vectorizer to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:19.622457Z",
     "start_time": "2018-03-18T06:30:19.285302Z"
    }
   },
   "outputs": [],
   "source": [
    "# count_vectorizer = count_vectorizer.fit(X_train)\n",
    "tfidf_vectorizer = tfidf_vectorizer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Transform X_train and X_test using 2 vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:20.952166Z",
     "start_time": "2018-03-18T06:30:20.498449Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train_count = count_vectorizer.transform(X_train)\n",
    "# X_test_count = count_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Convert sparse matrix into dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:21.707633Z",
     "start_time": "2018-03-18T06:30:21.675129Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train_tfidf.toarray()\n",
    "X_test = X_test_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:22.240537Z",
     "start_time": "2018-03-18T06:30:22.225775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tranining points 2382\n",
      "Number of test points 1584\n"
     ]
    }
   ],
   "source": [
    "num_train = Y_train.shape[0]\n",
    "num_test = Y_test.shape[0]\n",
    "\n",
    "print('Number of tranining points', num_train)\n",
    "print('Number of test points', num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:22.708616Z",
     "start_time": "2018-03-18T06:30:22.701929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of X : 891\n"
     ]
    }
   ],
   "source": [
    "dim_X = X_train.shape[1]\n",
    "print('Dimension of X : %d'%dim_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:23.221847Z",
     "start_time": "2018-03-18T06:30:23.214565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels :  [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(Y_test)\n",
    "print('Labels : ',labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitting classifiers with TF-IDF vectorizer and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Placeholder\n",
    "- Shape of the placeholder for inputs : [batch_size, dim_X]\n",
    "- Shape of the placeholder for outputs : [batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:24.253482Z",
     "start_time": "2018-03-18T06:30:24.247471Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, dim_X], name='Inputs')\n",
    "Y = tf.placeholder(tf.int32, [None], name='Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build the model\n",
    "- TF-Slim을 이용하여 아주 간단하게 모델을 선언\n",
    "- https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:25.435565Z",
     "start_time": "2018-03-18T06:30:25.419960Z"
    }
   },
   "outputs": [],
   "source": [
    "def fully_connected(inputs, num_labels, hidden_sizes=[100, 100], scope='FCN'):\n",
    "    \"\"\"\n",
    "    [fully_connected] n개의 hidden layer를 갖는 feed-forward network 생성 (with TF-Slim)\n",
    "    \n",
    "    [Args]\n",
    "      - inputs: 입력 데이터를 위한 placeholder\n",
    "      - hidden_sizes: a list (은닉 노드 수를 원하는 층 수 만큼 기록한 리스트)\n",
    "      - Scope: default value (\"FCN\")\n",
    "    \"\"\"\n",
    "    # Inputs에서 1차원의 텐서들이 placeholder로 들어온다고 가정\n",
    "    input_dim = inputs.get_shape()[1]\n",
    "\n",
    "    # Number of hidden layers\n",
    "    num_hidden_layers = len(hidden_sizes)\n",
    "    \n",
    "    with slim.arg_scope([slim.fully_connected],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_initializer=tf.contrib.layers.xavier_initializer(),\n",
    "                        biases_initializer=tf.constant_initializer(0.0),\n",
    "                        weights_regularizer=slim.l2_regularizer(0.05)):\n",
    "        net = inputs\n",
    "        for i in range(num_hidden_layers):\n",
    "            scope_name = 'fc' + str(i)\n",
    "            net = slim.fully_connected(inputs=net, num_outputs=hidden_sizes[i], scope=scope_name)\n",
    "        net = slim.fully_connected(inputs=net, num_outputs=num_labels, activation_fn=None, scope='logits')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:25.955361Z",
     "start_time": "2018-03-18T06:30:25.906017Z"
    }
   },
   "outputs": [],
   "source": [
    "logits = fully_connected(inputs=X, num_labels=len(labels), hidden_sizes=[100, 100], scope='FCN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cost function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:26.733800Z",
     "start_time": "2018-03-18T06:30:26.647223Z"
    }
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train_op = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Predicting operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:27.467770Z",
     "start_time": "2018-03-18T06:30:27.459760Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = tf.argmax(logits, axis=1)\n",
    "correct_prediction = tf.nn.in_top_k(logits, Y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:30:49.444357Z",
     "start_time": "2018-03-18T06:30:49.441647Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:31:20.264901Z",
     "start_time": "2018-03-18T06:31:20.259601Z"
    }
   },
   "outputs": [],
   "source": [
    "# 결과를 저장할 리스트를 작성\n",
    "train_cost_list = list()\n",
    "test_cost_list = list()\n",
    "test_accuracy_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:40:50.814504Z",
     "start_time": "2018-03-18T06:40:36.432039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 epoch] training cost  0.5378\n",
      "[2 epoch] training cost  0.1494\n",
      "[3 epoch] training cost  0.0748\n",
      "[4 epoch] training cost  0.0561\n",
      "[5 epoch] training cost  0.0741\n",
      "[6 epoch] training cost  0.0613\n",
      "[7 epoch] training cost  0.0719\n",
      "[8 epoch] training cost  0.0497\n",
      "[9 epoch] training cost  0.0483\n",
      "[10 epoch] training cost  0.0519\n",
      "\t[10 epoch] test accuracy 0.8068\n",
      "[11 epoch] training cost  0.0518\n",
      "[12 epoch] training cost  0.0439\n",
      "[13 epoch] training cost  0.0342\n",
      "[14 epoch] training cost  0.0309\n",
      "[15 epoch] training cost  0.0308\n",
      "[16 epoch] training cost  0.0308\n",
      "[17 epoch] training cost  0.0309\n",
      "[18 epoch] training cost  0.0307\n",
      "[19 epoch] training cost  0.0307\n",
      "[20 epoch] training cost  0.0306\n",
      "\t[20 epoch] test accuracy 0.8081\n",
      "[21 epoch] training cost  0.0306\n",
      "[22 epoch] training cost  0.0306\n",
      "[23 epoch] training cost  0.0306\n",
      "[24 epoch] training cost  0.0306\n",
      "[25 epoch] training cost  0.0306\n",
      "[26 epoch] training cost  0.0305\n",
      "[27 epoch] training cost  0.0305\n",
      "[28 epoch] training cost  0.0305\n",
      "[29 epoch] training cost  0.0305\n",
      "[30 epoch] training cost  0.0305\n",
      "\t[30 epoch] test accuracy 0.8068\n",
      "[31 epoch] training cost  0.0305\n",
      "[32 epoch] training cost  0.0304\n",
      "[33 epoch] training cost  0.0304\n",
      "[34 epoch] training cost  0.0304\n",
      "[35 epoch] training cost  0.0304\n",
      "[36 epoch] training cost  0.0304\n",
      "[37 epoch] training cost  0.0304\n",
      "[38 epoch] training cost  0.0303\n",
      "[39 epoch] training cost  0.0303\n",
      "[40 epoch] training cost  0.0303\n",
      "\t[40 epoch] test accuracy 0.8081\n",
      "[41 epoch] training cost  0.0303\n",
      "[42 epoch] training cost  0.0302\n",
      "[43 epoch] training cost  0.0302\n",
      "[44 epoch] training cost  0.0302\n",
      "[45 epoch] training cost  0.0302\n",
      "[46 epoch] training cost  0.0302\n",
      "[47 epoch] training cost  0.0301\n",
      "[48 epoch] training cost  0.0301\n",
      "[49 epoch] training cost  0.0301\n",
      "[50 epoch] training cost  0.0301\n",
      "\t[50 epoch] test accuracy 0.8087\n",
      "[51 epoch] training cost  0.0301\n",
      "[52 epoch] training cost  0.0301\n",
      "[53 epoch] training cost  0.0301\n",
      "[54 epoch] training cost  0.0301\n",
      "[55 epoch] training cost  0.0300\n",
      "[56 epoch] training cost  0.0299\n",
      "[57 epoch] training cost  0.0305\n",
      "[58 epoch] training cost  0.0300\n",
      "[59 epoch] training cost  0.0300\n",
      "[60 epoch] training cost  0.0300\n",
      "\t[60 epoch] test accuracy 0.8087\n",
      "[61 epoch] training cost  0.0300\n",
      "[62 epoch] training cost  0.0300\n",
      "[63 epoch] training cost  0.0300\n",
      "[64 epoch] training cost  0.0300\n",
      "[65 epoch] training cost  0.0300\n",
      "[66 epoch] training cost  0.0300\n",
      "[67 epoch] training cost  0.0300\n",
      "[68 epoch] training cost  0.0300\n",
      "[69 epoch] training cost  0.0300\n",
      "[70 epoch] training cost  0.0300\n",
      "\t[70 epoch] test accuracy 0.8081\n",
      "[71 epoch] training cost  0.0300\n",
      "[72 epoch] training cost  0.0300\n",
      "[73 epoch] training cost  0.0300\n",
      "[74 epoch] training cost  0.0300\n",
      "[75 epoch] training cost  0.0300\n",
      "[76 epoch] training cost  0.0300\n",
      "[77 epoch] training cost  0.0300\n",
      "[78 epoch] training cost  0.0300\n",
      "[79 epoch] training cost  0.0300\n",
      "[80 epoch] training cost  0.0300\n",
      "\t[80 epoch] test accuracy 0.8081\n",
      "[81 epoch] training cost  0.0300\n",
      "[82 epoch] training cost  0.0300\n",
      "[83 epoch] training cost  0.0300\n",
      "[84 epoch] training cost  0.0300\n",
      "[85 epoch] training cost  0.0300\n",
      "[86 epoch] training cost  0.0300\n",
      "[87 epoch] training cost  0.0300\n",
      "[88 epoch] training cost  0.0300\n",
      "[89 epoch] training cost  0.0300\n",
      "[90 epoch] training cost  0.0300\n",
      "\t[90 epoch] test accuracy 0.8081\n",
      "[91 epoch] training cost  0.0300\n",
      "[92 epoch] training cost  0.0300\n",
      "[93 epoch] training cost  0.0300\n",
      "[94 epoch] training cost  0.0300\n",
      "[95 epoch] training cost  0.0300\n",
      "[96 epoch] training cost  0.0300\n",
      "[97 epoch] training cost  0.0300\n",
      "[98 epoch] training cost  0.0300\n",
      "[99 epoch] training cost  0.0300\n",
      "[100 epoch] training cost  0.0300\n",
      "\t[100 epoch] test accuracy 0.8081\n",
      "\n",
      "\n",
      "Test accuracy : 0.8081\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Variable initialization\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Indices for construncting batches\n",
    "    start_idx = range(0, num_train, BATCH_SIZE)\n",
    "    end_idx = range(BATCH_SIZE, num_train + 1, BATCH_SIZE)\n",
    "    \n",
    "    NUM_BATCHES = len(start_idx)\n",
    "    \n",
    "    for epoch in range(0, NUM_EPOCHS):\n",
    "        # Set \"Train_cost\" as 0 before starting the epoch\n",
    "        train_cost = 0\n",
    "        \n",
    "        # Training Phrase\n",
    "        for start, end in zip(start_idx, end_idx):\n",
    "            \n",
    "            # Construnct the input batch\n",
    "            batch_xs = X_train[start:end]\n",
    "            batch_ys = Y_train[start:end]\n",
    "            \n",
    "            # Calculate cost\n",
    "            tmp_cost, _ = sess.run([cost, train_op], feed_dict={X:batch_xs, Y:batch_ys})\n",
    "            train_cost += tmp_cost\n",
    "            \n",
    "        train_cost = train_cost / NUM_BATCHES\n",
    "        train_cost_list.append(train_cost)\n",
    "        print(\"[{} epoch] training cost {: 0.4f}\".format((epoch + 1), train_cost))\n",
    "        \n",
    "        # Check test performance\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            test_cost, test_accuracy = sess.run([cost, accuracy], feed_dict={X: X_test, Y:Y_test})\n",
    "            test_cost_list.append(test_cost)\n",
    "            test_accuracy_list.append(test_accuracy)\n",
    "            print(\"\\t[{} epoch] test accuracy {:0.4f}\".format((epoch + 1), test_accuracy))\n",
    "            \n",
    "    # Test phase\n",
    "    Y_test_hat, test_accuracy = sess.run([predict, accuracy], feed_dict = {X:X_test, Y:Y_test})\n",
    "    print(\"\\n\")\n",
    "    print(\"Test accuracy : {:0.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:41:04.693352Z",
     "start_time": "2018-03-18T06:41:04.686975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, ..., 3, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:41:10.878988Z",
     "start_time": "2018-03-18T06:41:10.876105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 2, ..., 3, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-18T06:41:36.438068Z",
     "start_time": "2018-03-18T06:41:36.433122Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[325  23  34  13]\n",
      " [ 19 328  28  22]\n",
      " [ 21  44 292  37]\n",
      " [ 13  30  20 335]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test, Y_test_hat)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RL)",
   "language": "python",
   "name": "reinforcement_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
