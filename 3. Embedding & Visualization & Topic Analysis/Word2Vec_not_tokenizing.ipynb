{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T07:42:42.599766Z",
     "start_time": "2018-03-13T07:42:42.165773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization_TSNE_MDS_LLE_ISOMAP.ipynb에서 단어를 custom_tokenizer를 수행한 이후, 문서 벡터로 표현하여 2차원 벡터로 학습하였음\n",
    "\n",
    "이 경우는 노이즈한 결과가 나오이기도 함. 시각화는 대상을 좋은 벡터로 표햔한 다음에 (representation learning), 이를 저차원의 벡터로 다시 한 번 압축함\n",
    "\n",
    "대부분의 단어/문서 시각화는 Word2Vec, Doc2Vec, Glove, RNN, RBM 등으로 질 좋은 고차원 벡터의 representation을 얻은 뒤, 이를 다시 한 번 2차원 벡터로 압축하고 있음. 한 번에 풀리는 것은 존재하지 않음. 시각화와 같이 노이즈에 민감한 작업에서는 더더욱 그러한 경향이 있음\n",
    "\n",
    "동일한 문서에 대하여 토크나이징을 하지 않은 체로 어절을 그대로 Word2Vec학습을 수행함. 데이터의 숫자가 정말로 풍부하고, 모델이 수많은 어절을 드대로 학습할 수 있을 만큼의 하드웨어면, 어절을 그대로 Word2Vec 학습하여도 그 결과는 충분히 쓸만하지만, 목적이 다를 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T07:42:43.419306Z",
     "start_time": "2018-03-13T07:42:43.410078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \n",
      "\n",
      "1 : 의원 60명 내무장관에게 서한 철거 때 어린이 안전 신경 써야\n",
      "\n",
      "2 : 보호자 없는 아동 난민 70명은 영국에 도착\n",
      "\n",
      "3 : 22일 경찰에 돌 던지는 칼레 난민 연합뉴스\n",
      "\n",
      "4 : 파리 런던 연합뉴스 박성진 황정우 특파원 프랑스 칼레 난민촌 철거를 이틀 앞둔 22일 현지시간 난민촌 주변에서 현지 경찰과 난민이 충돌했다고 현지 프랑스앵포가 보도했다\n",
      "\n",
      "5 : 난민촌 철거에 반대하는 난민 50명가량은 경찰을 향해 유리병과 돌을 던졌으며 경찰은 연막탄을 쏘면서 이들을 해산했다\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_fname= '/home/paulkim/workspace/python/Korean_NLP/data/corpus_10days/news/2016-10-24_article_all_normed.txt'\n",
    "word2vec_fname = '/home/paulkim/workspace/python/Korean_NLP/data/corpus_10days/models/2016-10-24_news_word2vec_model.pkl'\n",
    "\n",
    "TRAIN_WORD2VEC = True\n",
    "\n",
    "from corpus import Corpus\n",
    "corpus = Corpus(corpus_fname, iter_sent=True)\n",
    "\n",
    "i = 0\n",
    "for idx, text in enumerate(corpus):\n",
    "    i+=1\n",
    "    print(\"%d : %s\\n\"%(idx, text))\n",
    "    if i == 6:  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T07:42:53.013647Z",
     "start_time": "2018-03-13T07:42:52.789233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213087"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doublespace line spliter이기 때문에 Word2VecCorpus는 ''를 기준으로 doc을 sents로 나눈 뒤, 각 sent를 다시 한 번 split()하여 word list로 yield함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T07:42:55.790962Z",
     "start_time": "2018-03-13T07:42:55.771395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['의원', '60명', '내무장관에게', '서한', '철거', '때', '어린이', '안전', '신경', '써야']\n",
      "['보호자', '없는', '아동', '난민', '70명은', '영국에', '도착']\n",
      "['22일', '경찰에', '돌', '던지는', '칼레', '난민', '연합뉴스']\n",
      "['파리', '런던', '연합뉴스', '박성진', '황정우', '특파원', '프랑스', '칼레', '난민촌', '철거를', '이틀', '앞둔', '22일', '현지시간', '난민촌', '주변에서', '현지', '경찰과', '난민이', '충돌했다고', '현지', '프랑스앵포가', '보도했다']\n",
      "['난민촌', '철거에', '반대하는', '난민', '50명가량은', '경찰을', '향해', '유리병과', '돌을', '던졌으며', '경찰은', '연막탄을', '쏘면서', '이들을', '해산했다']\n",
      "['이', '과정에서', '별다른', '부상자는', '나오지', '않았다']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class Word2VecCorpus:\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        if not os.path.isfile(fname):\n",
    "            print('File not found : %s'%fname)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        with open(self.fname, encoding='utf-8') as f:\n",
    "            for doc in f:\n",
    "                for sent in doc.strip().split('  '):\n",
    "                    sent = sent.strip()\n",
    "                    if not sent:\n",
    "                        continue\n",
    "                    yield sent.split()\n",
    "                    \n",
    "word2vec_corpus = Word2VecCorpus(corpus_fname)\n",
    "\n",
    "for num_sent, sent in enumerate(word2vec_corpus):\n",
    "    if num_sent > 5: break\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T07:49:07.588771Z",
     "start_time": "2018-03-13T07:48:47.689641Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "\n",
    "# 전부 때려넣어서 end-to-end로 접근\n",
    "if TRAIN_WORD2VEC:\n",
    "    word2vec_model = Word2Vec(word2vec_corpus, min_count=30)\n",
    "    with open(word2vec_fname, 'wb') as f:\n",
    "        pickle.dump(word2vec_model, f)\n",
    "        \n",
    "else:\n",
    "    with open(word2vec_fname, 'rb') as f:\n",
    "        word2vec_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T07:49:08.859231Z",
     "start_time": "2018-03-13T07:49:08.855976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18329"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec_model.wv.syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T07:49:18.162837Z",
     "start_time": "2018-03-13T07:49:18.159089Z"
    }
   },
   "outputs": [],
   "source": [
    "test_words = ['김무성', \n",
    "              '박근혜', \n",
    "              '문재인', \n",
    "              '국방부', \n",
    "              '정부', \n",
    "              '국정원', \n",
    "              '대통령', \n",
    "              '축구', \n",
    "              '외교', \n",
    "              '정책', \n",
    "              '군대', \n",
    "              '미국', \n",
    "              '일본', \n",
    "              '중국'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어절만 이용하여 학습했음에도 불구하고, 김무성의 유사어로 정치인들이 등장함을 볼 수 있음. 이는 뉴스 코퍼스에서는 정치인의 이름만 적고 띄어스기를 하는 경우도 충분하기 때문임\n",
    "\n",
    "하지만 '김무성 -대표도'와 같은 유사 어절이 등장하는 것은, 뉴스에서 '김무성'으로만 적는 경우와 '김무성 대표도'로 적는 경우가 혼재되어 있어서, '대표도'의 문맥이 '김무성'의 문맥과 유사하였기 때문임\n",
    "\n",
    "비슷한 의미로, 박근혜 - 박 (6251)의 경우에는 '박근혜-대통령', '박 대통령'이 번갈아가며 이용되었기 때문임\n",
    "\n",
    "그러나 국정원의 경우에는 총 42번 나왔으며, '박근혜 대통령', '박 대통령'이 번갈아가며 이용되었기 때문임.\n",
    "\n",
    "그러나, 국정원의 경우에는 총 42번 나왔으며, min_count=30으로 하였기 때문에 18000여개의 단어 중에서는 infrequent 한 편에 속함. 그리고 이 때의 유사 어절들은 문맥상 잘 어울리지 않는 어절임\n",
    "\n",
    "    Seed word = 국정원\n",
    "    Vocab(count:42, index:12977, sample_int:4294967296)\n",
    "    국정원 - 크리스 (33) (0.733)\n",
    "    국정원 - 자격으로 (34) (0.716)\n",
    "    국정원 - 남편인 (34) (0.714)\n",
    "    국정원 - 출간한 (36) (0.708)\n",
    "    국정원 - 단국대 (33) (0.707)\n",
    "    국정원 - 준비는 (35) (0.707)\n",
    "    국정원 - 대우학원 (34) (0.705)\n",
    "    국정원 - 최경희 (32) (0.702)\n",
    "    국정원 - 정동구 (31) (0.697)\n",
    "    국정원 - 인터뷰가 (36) (0.696)\n",
    "    \n",
    "Word2Vec에서는 infrequent한 단어(어절)들의 유사 단어(어절)들은 infrequent한 경향이 있음. **빈도수가 충분하지 않을 경우**에는 학습이 잘 되지 않는 것으로 해석할 수 있음\n",
    "\n",
    "어절을 그대로 학습할 경우에는, 아래와 같이 대통령의 유사어절로 '대통령 + 조사'의 어절들이 자주 등장함\n",
    "\n",
    "    Seed word = 대통령\n",
    "    Vocab(count:3411, index:89, sample_int:4294967296)\n",
    "    대통령 - 대통령의 (3074) (0.827)\n",
    "    대통령 - 대통령을 (287) (0.780)\n",
    "    대통령 - 대통령과 (437) (0.768)\n",
    "    대통령 - 대통령도 (125) (0.746)\n",
    "    대통령 - 대통령이 (5054) (0.742)\n",
    "    대통령 - 대통령에 (255) (0.725)\n",
    "    대통령 - 대통령은 (2852) (0.720)\n",
    "    대통령 - 대통령에게 (203) (0.711)\n",
    "    대통령 - 대통령이다 (54) (0.678)\n",
    "    대통령 - 대통령께서 (280) (0.672)\n",
    "    \n",
    "\n",
    "목적이 **원하는 Language model을 학습하는 것**이며, 이 결과는 **유용**함. \n",
    "\n",
    "하지만, **문맥적으로 유사한 단어들을 찾기 위해 Word2Vec을 학습하는 것이 목적**이면, 어절을 그대로 학습하는 것보다 **토크나이징**을 한 뒤, 이를 학습하여 이용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-13T08:07:57.372728Z",
     "start_time": "2018-03-13T08:07:57.189307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Seed word = 김무성\n",
      "Vocab(count:332, index:1414, sample_int:4294967296)\n",
      "김무성 - 김종인 (165) (0.937)\n",
      "김무성 - 유승민 (160) (0.891)\n",
      "김무성 - 안철수 (345) (0.891)\n",
      "김무성 - 손학규 (270) (0.883)\n",
      "김무성 - 오세훈 (72) (0.881)\n",
      "김무성 - 최경환 (43) (0.877)\n",
      "김무성 - 대표도 (106) (0.867)\n",
      "김무성 - 김부겸 (100) (0.844)\n",
      "김무성 - 강석호 (43) (0.843)\n",
      "김무성 - 개헌론자인 (36) (0.828)\n",
      "\n",
      "\n",
      "Seed word = 박근혜\n",
      "Vocab(count:4420, index:62, sample_int:4294967296)\n",
      "박근혜 - 이승만 (36) (0.747)\n",
      "박근혜 - 박정희 (216) (0.723)\n",
      "박근혜 - 마두로 (46) (0.720)\n",
      "박근혜 - 박 (6251) (0.719)\n",
      "박근혜 - 뒤늦은 (30) (0.711)\n",
      "박근혜 - 국정과 (37) (0.698)\n",
      "박근혜 - 두테르테 (218) (0.679)\n",
      "박근혜 - 민생에 (38) (0.674)\n",
      "박근혜 - 전두환 (44) (0.668)\n",
      "박근혜 - 오바마 (209) (0.663)\n",
      "\n",
      "\n",
      "Seed word = 문재인\n",
      "Vocab(count:940, index:392, sample_int:4294967296)\n",
      "문재인 - 손학규 (270) (0.869)\n",
      "문재인 - 김종인 (165) (0.863)\n",
      "문재인 - 안철수 (345) (0.863)\n",
      "문재인 - 비서실장이 (97) (0.851)\n",
      "문재인 - 문 (932) (0.851)\n",
      "문재인 - 장관의 (162) (0.834)\n",
      "문재인 - 송민순 (663) (0.807)\n",
      "문재인 - 김무성 (332) (0.795)\n",
      "문재인 - 유승민 (160) (0.785)\n",
      "문재인 - 안보실장이 (81) (0.781)\n",
      "\n",
      "\n",
      "Seed word = 국방부\n",
      "Vocab(count:247, index:2003, sample_int:4294967296)\n",
      "국방부 - 외교부 (391) (0.913)\n",
      "국방부 - 노동당 (63) (0.862)\n",
      "국방부 - 롯데그룹 (120) (0.849)\n",
      "국방부 - 윤병세 (80) (0.835)\n",
      "국방부 - 외무성 (74) (0.827)\n",
      "국방부 - 신동빈 (98) (0.825)\n",
      "국방부 - 대사관 (31) (0.823)\n",
      "국방부 - 차관급 (38) (0.821)\n",
      "국방부 - 차관보는 (106) (0.820)\n",
      "국방부 - 장관과 (73) (0.815)\n",
      "\n",
      "\n",
      "Seed word = 정부\n",
      "Vocab(count:1769, index:194, sample_int:4294967296)\n",
      "정부 - 정부의 (814) (0.824)\n",
      "정부 - 법인세 (212) (0.741)\n",
      "정부 - 정부에서 (76) (0.723)\n",
      "정부 - 정부는 (1002) (0.712)\n",
      "정부 - 정부가 (1017) (0.706)\n",
      "정부 - 법안 (79) (0.701)\n",
      "정부 - 경제민주화 (97) (0.695)\n",
      "정부 - 대통령과 (437) (0.679)\n",
      "정부 - 개정안 (81) (0.669)\n",
      "정부 - 정부와 (255) (0.665)\n",
      "\n",
      "\n",
      "Seed word = 국정원\n",
      "Vocab(count:42, index:12977, sample_int:4294967296)\n",
      "국정원 - 크리스 (33) (0.733)\n",
      "국정원 - 자격으로 (34) (0.716)\n",
      "국정원 - 남편인 (34) (0.714)\n",
      "국정원 - 출간한 (36) (0.708)\n",
      "국정원 - 단국대 (33) (0.707)\n",
      "국정원 - 준비는 (35) (0.707)\n",
      "국정원 - 대우학원 (34) (0.705)\n",
      "국정원 - 최경희 (32) (0.702)\n",
      "국정원 - 정동구 (31) (0.697)\n",
      "국정원 - 인터뷰가 (36) (0.696)\n",
      "\n",
      "\n",
      "Seed word = 대통령\n",
      "Vocab(count:3411, index:89, sample_int:4294967296)\n",
      "대통령 - 대통령의 (3074) (0.827)\n",
      "대통령 - 대통령을 (287) (0.780)\n",
      "대통령 - 대통령과 (437) (0.768)\n",
      "대통령 - 대통령도 (125) (0.746)\n",
      "대통령 - 대통령이 (5054) (0.742)\n",
      "대통령 - 대통령에 (255) (0.725)\n",
      "대통령 - 대통령은 (2852) (0.720)\n",
      "대통령 - 대통령에게 (203) (0.711)\n",
      "대통령 - 대통령이다 (54) (0.678)\n",
      "대통령 - 대통령께서 (280) (0.672)\n",
      "\n",
      "\n",
      "Seed word = 축구\n",
      "Vocab(count:43, index:12808, sample_int:4294967296)\n",
      "축구 - 전통의 (35) (0.866)\n",
      "축구 - 쉐보레 (30) (0.848)\n",
      "축구 - 넥슨 (31) (0.821)\n",
      "축구 - 예술의 (40) (0.817)\n",
      "축구 - 맥도날드 (49) (0.814)\n",
      "축구 - 샵 (32) (0.811)\n",
      "축구 - 주인도네시아 (32) (0.807)\n",
      "축구 - 강사 (41) (0.806)\n",
      "축구 - 중견 (68) (0.805)\n",
      "축구 - 오케스트라와 (37) (0.794)\n",
      "\n",
      "\n",
      "Seed word = 외교\n",
      "Vocab(count:166, index:3124, sample_int:4294967296)\n",
      "외교 - 국방 (71) (0.892)\n",
      "외교 - 통일 (88) (0.831)\n",
      "외교 - 사드 (72) (0.795)\n",
      "외교 - 한미 (96) (0.784)\n",
      "외교 - 양국 (120) (0.770)\n",
      "외교 - 북핵 (204) (0.769)\n",
      "외교 - 유엔 (548) (0.769)\n",
      "외교 - 안보 (361) (0.751)\n",
      "외교 - 배치 (93) (0.749)\n",
      "외교 - 문제와 (95) (0.745)\n",
      "\n",
      "\n",
      "Seed word = 정책\n",
      "Vocab(count:445, index:1017, sample_int:4294967296)\n",
      "정책 - 개혁 (118) (0.875)\n",
      "정책 - 개편 (263) (0.871)\n",
      "정책 - 방안이 (120) (0.809)\n",
      "정책 - 정책을 (306) (0.800)\n",
      "정책 - 문제 (632) (0.798)\n",
      "정책 - 규제를 (122) (0.788)\n",
      "정책 - 노동 (89) (0.788)\n",
      "정책 - 대북 (248) (0.783)\n",
      "정책 - 경제 (1278) (0.782)\n",
      "정책 - 갈등 (127) (0.781)\n",
      "\n",
      "\n",
      "Seed word = 미국\n",
      "Vocab(count:3311, index:92, sample_int:4294967296)\n",
      "미국 - 미국의 (601) (0.773)\n",
      "미국 - 중국 (2527) (0.737)\n",
      "미국 - 미 (598) (0.732)\n",
      "미국 - 영국 (668) (0.725)\n",
      "미국 - 일본 (1661) (0.717)\n",
      "미국 - 러시아 (229) (0.707)\n",
      "미국 - 중국의 (344) (0.688)\n",
      "미국 - 미국과 (215) (0.686)\n",
      "미국 - 유럽 (412) (0.681)\n",
      "미국 - 브렉시트 (124) (0.673)\n",
      "\n",
      "\n",
      "Seed word = 일본\n",
      "Vocab(count:1661, index:209, sample_int:4294967296)\n",
      "일본 - 중국 (2527) (0.833)\n",
      "일본 - 유럽 (412) (0.791)\n",
      "일본 - 영국 (668) (0.781)\n",
      "일본 - 미국과 (215) (0.762)\n",
      "일본 - 호주 (185) (0.757)\n",
      "일본 - 러시아 (229) (0.757)\n",
      "일본 - 대만 (143) (0.752)\n",
      "일본 - 한국과 (200) (0.738)\n",
      "일본 - 상하이 (114) (0.735)\n",
      "일본 - 프랑스 (662) (0.720)\n",
      "\n",
      "\n",
      "Seed word = 중국\n",
      "Vocab(count:2527, index:134, sample_int:4294967296)\n",
      "중국 - 일본 (1661) (0.833)\n",
      "중국 - 유럽 (412) (0.776)\n",
      "중국 - 중국의 (344) (0.756)\n",
      "중국 - 미국 (3311) (0.737)\n",
      "중국 - 미국과 (215) (0.731)\n",
      "중국 - 인도 (249) (0.719)\n",
      "중국 - 중국과 (125) (0.709)\n",
      "중국 - 상하이 (114) (0.703)\n",
      "중국 - 러시아 (229) (0.702)\n",
      "중국 - 호주 (185) (0.687)\n"
     ]
    }
   ],
   "source": [
    "for word in test_words:\n",
    "    if  (word in word2vec_model.wv.vocab) == False:\n",
    "        continue\n",
    "        \n",
    "    print('\\n\\nSeed word = %s'%word)\n",
    "    print(word2vec_model.wv.vocab[word])\n",
    "    for similar_word, sim in word2vec_model.most_similar(word):\n",
    "        print('%s - %s (%d) (%.3f)'%(word, similar_word, word2vec_model.wv.vocab[similar_word].count, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (python3_0901)",
   "language": "python",
   "name": "python3_0901"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
